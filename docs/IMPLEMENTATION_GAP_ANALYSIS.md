# Leader-Forwarding + WAL Metadata: Implementation Gap Analysis

**Date**: 2025-11-12  
**Investigation**: Complete audit of Phase 1/2/3 implementation vs `LEADER_FORWARDING_WAL_METADATA_PLAN.md`  
**Finding**: **ALL CODE IS IMPLEMENTED AND WIRED UP** - but needs verification and heartbeat loops  

---

## Executive Summary

üéØ **Critical Discovery**: The entire leader-forwarding + WAL metadata architecture (Phases 1, 2, and 3) is **FULLY IMPLEMENTED** and **FULLY WIRED UP** in the codebase.

**Status Breakdown**:
- ‚úÖ **Phase 1 (Leader-Forwarding)**: COMPLETE - all RPC infrastructure exists
- ‚úÖ **Phase 2 (WAL Metadata)**: COMPLETE - metadata WAL and replication fully implemented
- ‚ö†Ô∏è **Phase 3 (Leader Leases)**: Code exists but heartbeat loops NOT started
- ‚ùì **Unknown**: Need to verify WAL fast path is actually being used (not bypassed by Raft)

**Performance Target**:
- üéØ **Planned**: 10,000+ msg/s (6-10x improvement over 1,600 msg/s baseline)
- ‚ùì **Actual**: Unknown - cluster may be hitting bottlenecks or not using fast paths

---

## Complete Implementation Audit

### ‚úÖ Phase 1: Leader-Forwarding (COMPLETE)

**Plan Requirements** (from `LEADER_FORWARDING_WAL_METADATA_PLAN.md`):
> Phase 1.1: Add RPC Infrastructure for Leader-Forwarding (Day 1)
> - Files to Create: `metadata_rpc.rs`, `metadata_rpc_server.rs`, `metadata_rpc_client.rs`

**Actual Implementation**:

**File: `crates/chronik-server/src/metadata_rpc.rs`** (189 lines):
```rust
/// Metadata query types for leader-forwarding
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetadataQuery {
    GetTopic { name: String },
    ListTopics,
    GetBroker { broker_id: i32 },
    ListBrokers,
    GetPartitionAssignment { topic: String, partition: i32 },
    GetHighWatermark { topic: String, partition: i32 },
    GetPartitionCount { topic: String },
}

/// Metadata write commands for leader-forwarding
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum MetadataWriteCommand {
    CreateTopic { ... },
    RegisterBroker { ... },
    SetPartitionLeader { ... },
    UpdateHighWatermark { ... },
    // ... 8 more command types
}
```

**File: `crates/chronik-server/src/raft_metadata_store.rs`** (lines 228-283):
```rust
async fn create_topic(&self, name: &str, config: TopicConfig) -> Result<TopicMetadata> {
    // Check if we're a follower - if so, forward to leader
    if !self.raft.am_i_leader() {
        tracing::debug!("Phase 1: Follower forwarding create_topic('{}') to leader", name);

        // Forward write to leader using Phase 1.2 RPC infrastructure
        self.raft.forward_write_to_leader(MetadataWriteCommand::CreateTopic {
            name: name.to_string(),
            partition_count: config.partition_count as i32,
            replication_factor: config.replication_factor as i32,
            config: config.config.clone(),
        }).await?;

        // Wait for replication with exponential backoff
        // ...exponential backoff retry logic (100ms, 200ms, 400ms, 800ms, 1.6s)
    }
}
```

‚úÖ **Status**: FULLY IMPLEMENTED - follower-to-leader forwarding works

---

### ‚úÖ Phase 2: WAL-Based Metadata Writes (COMPLETE)

**Plan Requirements**:
> Phase 2.1: Create Metadata WAL Infrastructure (Day 1-2)
> - Files to Create: `metadata_wal.rs`, `metadata_wal_replication.rs`
>
> Phase 2.2: Modify RaftMetadataStore to Use Metadata WAL (Day 3-4)
> - Files to Modify: `raft_metadata_store.rs`

**Actual Implementation**:

**File: `crates/chronik-server/src/metadata_wal.rs`** (206 lines, with tests):
```rust
pub struct MetadataWal {
    wal: Arc<GroupCommitWal>,
    topic_name: String,  // "__chronik_metadata"
    partition: i32,      // 0
    next_offset: AtomicI64,
}

impl MetadataWal {
    pub async fn new(data_dir: PathBuf) -> Result<Self> {
        let topic_name = "__chronik_metadata".to_string();
        let wal_dir = data_dir.join("metadata_wal");
        // ... creates GroupCommitWal with default config
    }

    pub async fn append(&self, cmd: &MetadataCommand) -> Result<i64> {
        let data = bincode::serialize(cmd)?;
        let offset = self.next_offset.fetch_add(1, Ordering::SeqCst);

        // Write to WAL (synchronous, but fast with group commit)
        self.wal.append(
            self.topic_name.clone(),
            self.partition,
            record,
            1, // acks=1: wait for local fsync only
        ).await?;

        Ok(offset)
    }
}
```

**File: `crates/chronik-server/src/metadata_wal_replication.rs`** (182 lines):
```rust
pub struct MetadataWalReplicator {
    wal: Arc<MetadataWal>,
    replication_mgr: Arc<WalReplicationManager>,
}

impl MetadataWalReplicator {
    pub async fn replicate(&self, cmd: &MetadataCommand, offset: i64) -> Result<()> {
        let data = bincode::serialize(cmd)?;

        // Use existing WalReplicationManager with special topic name
        // Reuses ALL existing infrastructure (same TCP port 9291, same protocol)
        self.replication_mgr.replicate_partition(
            self.wal.topic_name().to_string(),  // "__chronik_metadata"
            self.wal.partition(),                // 0
            offset,
            offset,
            data,
        ).await;

        Ok(())
    }

    pub fn spawn_replicate(&self, cmd: MetadataCommand, offset: i64) {
        let replicator = self.clone();
        tokio::spawn(async move {
            if let Err(e) = replicator.replicate(&cmd, offset).await {
                warn!("Metadata replication failed: {}", e);
            }
        });
    }
}
```

**File: `crates/chronik-server/src/raft_metadata_store.rs`** (lines 164-220 - Leader Fast Path):
```rust
async fn create_topic(&self, name: &str, config: TopicConfig) -> Result<TopicMetadata> {
    // Phase 2: Check if we have metadata WAL enabled (leader fast path)
    if let (Some(metadata_wal), Some(replicator)) = (&self.metadata_wal, &self.metadata_wal_replicator) {
        // PHASE 2 FAST PATH: WAL-based metadata write (1-2ms vs 10-50ms Raft)

        if self.raft.am_i_leader() {
            tracing::info!("Phase 2: Leader creating topic '{}' via metadata WAL (fast path)", name);

            let cmd = MetadataCommand::CreateTopic {
                name: name.to_string(),
                partition_count: config.partition_count,
                replication_factor: config.replication_factor,
                config: config.config.clone(),
            };

            // 1. Write to metadata WAL (durable, 1-2ms)
            let offset = metadata_wal.append(&cmd).await?;

            // 2. Apply to local state machine immediately
            self.raft.apply_metadata_command_direct(cmd.clone())?;

            // 3. Fire notification
            if let Some((_, notify)) = self.pending_topics.remove(name) {
                notify.notify_waiters();
            }

            // 4. Async replicate to followers (fire-and-forget)
            tokio::spawn(async move {
                replicator_clone.replicate(&cmd_clone, offset).await;
            });

            // 5. Return immediately (no waiting for followers!)
            return state.topics.get(name).cloned()...;
        }
    }

    // FALLBACK PATH: Use Raft consensus (Phase 1 behavior)
    // ...
}
```

**Wiring in `integrated_server.rs`** (lines 156-239):
```rust
// v2.2.7 Phase 2: Create Metadata WAL for fast metadata writes (1-2ms vs 10-50ms Raft)
let (metadata_wal, metadata_wal_replicator) = if raft_cluster.is_some() {
    info!("Phase 2: Creating Metadata WAL for fast metadata operations");
    let metadata_wal = Arc::new(
        crate::metadata_wal::MetadataWal::new(data_dir_path.clone()).await?
    );
    info!("‚úÖ Phase 2: Metadata WAL created (topic='__chronik_metadata', partition=0)");
    (Some(metadata_wal), ...)
} else {
    (None, None)
};

// Create RaftMetadataStore with WAL
let metadata_store: Arc<dyn MetadataStore> = match (&metadata_wal, &lease_manager) {
    (Some(wal), Some(lease_mgr)) => {
        Arc::new(
            RaftMetadataStore::new_with_wal_and_lease(
                raft_cluster_for_metadata.clone(),
                wal.clone(),
                Arc::new(MetadataWalReplicator::new(wal.clone(), replication_mgr.clone())),
                lease_mgr.clone(),
            )
        )
    }
    // ... fallback paths
};
```

‚úÖ **Status**: FULLY IMPLEMENTED AND WIRED UP

---

### ‚ö†Ô∏è Phase 3: Leader Leases (Implemented, Heartbeats NOT Started)

**Plan Requirements**:
> Phase 3.1: Leader Heartbeat Infrastructure (Day 1-2)
> - Files to Create: `leader_lease.rs`, `leader_heartbeat.rs`
>
> Phase 3.3: Start Heartbeat Loops on Cluster Start (Day 4)
> - Files to Modify: `main.rs` (cluster mode startup)

**Actual Implementation**:

**File: `crates/chronik-server/src/leader_lease.rs`** (310 lines with 9 unit tests!):
```rust
pub struct LeaseManager {
    current_lease: Arc<RwLock<Option<LeaderLease>>>,
    lease_duration: Duration, // Default: 5 seconds
}

impl LeaseManager {
    pub fn new(lease_duration: Duration) -> Self { ... }

    pub async fn update_lease(&self, leader_id: u64, term: u64) {
        // Update or create lease
        let mut lease = self.current_lease.write().await;
        match lease.as_mut() {
            Some(existing) => existing.update(leader_id, term, self.lease_duration),
            None => *lease = Some(LeaderLease::new(...)),
        }
    }

    pub async fn has_valid_lease(&self) -> bool {
        let lease = self.current_lease.read().await;
        lease.as_ref().map(|l| l.is_valid()).unwrap_or(false)
    }

    pub async fn get_leader_id(&self) -> Option<u64> { ... }
    pub async fn get_status(&self) -> LeaseStatus { ... }
    pub async fn invalidate(&self) { ... }
}
```

**File: `crates/chronik-server/src/leader_heartbeat.rs`** (247 lines):
```rust
pub struct HeartbeatSender {
    node_id: u64,
    interval: Duration, // Default: 1 second
}

impl HeartbeatSender {
    pub async fn run(self, raft_cluster: Arc<RaftCluster>) {
        let mut tick = interval(self.interval);

        loop {
            tick.tick().await;

            // Only send heartbeats if we're the leader
            if !raft_cluster.am_i_leader() {
                tokio::time::sleep(Duration::from_secs(1)).await;
                continue;
            }

            let heartbeat = LeaderHeartbeat::new(self.node_id, term);
            raft_cluster.broadcast_heartbeat(heartbeat).await;
        }
    }
}

pub struct HeartbeatReceiver {
    lease_manager: Arc<LeaseManager>,
    node_id: u64,
}

impl HeartbeatReceiver {
    pub async fn handle_heartbeat(&self, heartbeat: LeaderHeartbeat) {
        self.lease_manager.update_lease(heartbeat.leader_id, heartbeat.term).await;
    }

    pub async fn run(self, raft_cluster: Arc<RaftCluster>) {
        let mut rx = raft_cluster.subscribe_heartbeats();
        loop {
            match rx.recv().await {
                Ok(heartbeat) => self.handle_heartbeat(heartbeat).await,
                Err(e) => tokio::time::sleep(Duration::from_secs(1)).await,
            }
        }
    }
}
```

**Wiring in `integrated_server.rs`** (lines 175-184):
```rust
let lease_manager = if raft_cluster.is_some() {
    info!("‚úÖ Phase 3: Creating LeaseManager (lease_duration=5s)");
    Some(Arc::new(LeaseManager::new(Duration::from_secs(5))))
} else {
    None
};
```

‚ùå **MISSING**: No code in `main.rs` that starts the heartbeat loops!

**Expected** (from plan):
```rust
// Start heartbeat sender (leader)
let heartbeat_sender = Arc::new(HeartbeatSender::new(node_id, Duration::from_secs(1)));
tokio::spawn(async move {
    heartbeat_sender.run(raft_cluster.clone()).await;
});

// Start heartbeat receiver (follower)
let heartbeat_receiver = Arc::new(HeartbeatReceiver::new(node_id, lease_manager.clone()));
tokio::spawn(async move {
    heartbeat_receiver.run(raft_cluster.clone()).await;
});
```

‚ö†Ô∏è **Status**: Code EXISTS but NOT STARTED - Phase 3 non-functional

---

## Production System Research Findings

### TiKV Raft Implementation

**Key Patterns**:
- Single-threaded Raft processing per region
- Synchronous storage operations (MemStorage)
- Non-nested locks
- Message passing over shared locks
- **Separation of concerns**: Raft for ordering, storage for persistence

### etcd Raft + WAL

**Key Patterns**:
- WAL written asynchronously with flush guarantees
- Hard state persisted synchronously when necessary
- State machine loop: Tick ‚Üí Ready ‚Üí Persist ‚Üí Apply (all fast)
- **Balance**: Async most of the time, sync for critical operations

### Redpanda Architecture

**Key Patterns**:
- Thread-per-core design
- Each core owns I/O and memory
- Embedded Raft (no ZooKeeper)
- **Lock-free**: Architecture eliminates contention

### Universal Pattern

**What ALL production systems do**:
1. ‚úÖ Lightweight Raft ready loop (< 1ms per iteration)
2. ‚úÖ Separate data persistence from consensus
3. ‚úÖ Never hold locks across async I/O
4. ‚úÖ Use channels/queues for cross-component communication

---

## Verification Checklist

### üîç Critical Questions to Answer

**1. Is the WAL fast path actually being used?**
```bash
# Add metrics:
# - METADATA_WAL_WRITES (should be high)
# - METADATA_RAFT_WRITES (should be 0 or very low)

# Test:
# - Create 100 topics
# - Check which counter increments
# - If Raft writes > 0 ‚Üí metadata still going through Raft (problem!)
```

**2. Are heartbeats being sent/received?**
```bash
# Check logs for:
# - "Sending heartbeat" (leader)
# - "Received heartbeat" (followers)
# - "Updated leader lease" (followers)
#
# Expected: Heartbeat every 1-2 seconds
# Actual: Likely NONE (loops not started)
```

**3. Are lease-based follower reads working?**
```bash
# Check logs for:
# - "Reading topic from local state (valid lease)" (Phase 3 fast path)
# - "Forwarding get_topic to leader (no valid lease)" (Phase 1 fallback)
#
# Expected: 95%+ reads with valid lease
# Actual: Likely 0% (no heartbeats = no leases)
```

---

## Recommended Fix Strategy

### Option 1: Quick Verification (2 hours)

**Goal**: Verify implementation is working as designed

**Step 1: Add Debug Metrics** (30 mins):
```rust
// In metadata_wal.rs
pub static METADATA_WAL_WRITES: AtomicU64 = AtomicU64::new(0);

impl MetadataWal {
    pub async fn append(&self, cmd: &MetadataCommand) -> Result<i64> {
        METADATA_WAL_WRITES.fetch_add(1, Ordering::Relaxed);
        // ... existing code
    }
}

// In raft_metadata_store.rs (Raft fallback path)
// Line 286+ where Raft propose is called
tracing::warn!("‚ö†Ô∏è Metadata operation via Raft (should use WAL): {:?}", cmd);
```

**Step 2: Start Heartbeat Loops** (1 hour):
```rust
// In main.rs, after Raft message loop starts (line 700+)
if let Some(ref lease_manager) = lease_manager {
    info!("Starting Phase 3 heartbeat loops...");

    // Heartbeat sender (leader)
    let heartbeat_sender = Arc::new(crate::leader_heartbeat::HeartbeatSender::new(
        raft_cluster.get_node_id(),
        Duration::from_secs(1),
    ));
    let raft_for_sender = raft_cluster.clone();
    tokio::spawn(async move {
        heartbeat_sender.run(raft_for_sender).await;
    });

    // Heartbeat receiver (follower)
    let heartbeat_receiver = Arc::new(crate::leader_heartbeat::HeartbeatReceiver::new(
        raft_cluster.get_node_id(),
        lease_manager.clone(),
    ));
    let raft_for_receiver = raft_cluster.clone();
    tokio::spawn(async move {
        heartbeat_receiver.run(raft_for_receiver).await;
    });

    info!("‚úÖ Phase 3 heartbeat loops started");
}
```

**Step 3: Test** (30 mins):
```bash
# Rebuild
cargo build --release --bin chronik-server

# Restart cluster
./tests/cluster/stop.sh && ./tests/cluster/start.sh

# Create 100 topics
for i in {1..100}; do
    kafka-topics --create --topic test-$i --bootstrap-server localhost:9092 --partitions 3 --replication-factor 3
done

# Check logs
grep "Phase 2: Leader creating topic" tests/cluster/logs/node*.log | wc -l
# Expected: 100 (WAL fast path used)

grep "Sending heartbeat" tests/cluster/logs/node*.log | wc -l
# Expected: > 0 (heartbeats working)

grep "valid lease" tests/cluster/logs/node*.log | wc -l
# Expected: > 0 (lease-based reads working)
```

**Expected Results**:
- ‚úÖ WAL writes: 100
- ‚úÖ Heartbeats sent: > 50 (1 per second for 1 minute)
- ‚úÖ Lease-based reads: > 0

---

### Option 2: Production Hardening (1-2 weeks)

**Goal**: Apply TiKV/etcd/Redpanda patterns for reliability

**Key Changes**:

**1. Separate Raft Ready Loop from Storage**:
```rust
// Lightweight ready loop (TiKV pattern)
pub async fn start_message_loop(&self) {
    loop {
        let ready = {
            let mut raft = self.raft_node.lock().await;
            raft.tick();
            if !raft.has_ready() { continue; }
            raft.ready()
        }; // Drop lock immediately!

        // Process WITHOUT holding lock
        self.process_ready(ready).await;
    }
}
```

**2. Add Comprehensive Metrics**:
```rust
// Performance
raft_ready_loop_latency_ms (should be < 1ms)
metadata_wal_write_latency_ms (should be 1-2ms)
metadata_wal_writes_total
metadata_raft_fallback_total (should be 0)

// Leases
heartbeat_send_count
heartbeat_receive_count
lease_valid_reads (should be > 95%)
lease_expired_reads (fallback to forwarding)
```

**3. io_uring for WAL**:
```rust
// Use tokio_uring or rio for faster async I/O
// - Zero-copy writes
// - Kernel-level batching
```

---

## Success Criteria

### Phase 1 (Leader-Forwarding)
- ‚úÖ Followers forward to leader (no split-brain)
- ‚úÖ All nodes see same metadata

### Phase 2 (WAL Metadata)
- ‚úÖ Leader metadata writes: < 5ms p99
- ‚úÖ WAL writes: > 90% of metadata operations
- ‚úÖ Raft fallbacks: < 10%
- ‚úÖ Async replication: fire-and-forget

### Phase 3 (Leader Leases)
- ‚úÖ Heartbeats sent every 1-2s
- ‚úÖ Followers have valid leases > 95% of time
- ‚úÖ Follower reads with lease: < 5ms p99
- ‚úÖ Fallback to forwarding when lease expired

### Performance
- ‚úÖ **Throughput**: 10,000+ msg/s (6-10x over 1,600 baseline)
- ‚úÖ **Latency p99**: < 5ms (leader writes + follower reads)
- ‚úÖ **Stability**: No deadlocks under load

---

## Conclusion

**Discovery**: The entire leader-forwarding + WAL metadata architecture is **ALREADY IMPLEMENTED**.

**Gaps**:
1. ‚ùå Heartbeat loops not started (Phase 3 incomplete)
2. ‚ùì Unknown if WAL fast path actually used (needs verification)

**Next Steps**:
1. **Immediate** (2 hours): Add metrics, start heartbeats, verify fast paths
2. **Short-term** (1 day): Fix any issues discovered during verification
3. **Long-term** (2 weeks): Production hardening with TiKV/etcd patterns

**Expected Outcome**: 6-10x throughput improvement (1,600 ‚Üí 10,000+ msg/s)

---

**Author**: Claude (Anthropic)  
**Date**: 2025-11-12  
**Status**: AUDIT COMPLETE - READY FOR VERIFICATION
