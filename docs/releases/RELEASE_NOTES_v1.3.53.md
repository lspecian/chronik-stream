# Release Notes - v1.3.53

**Release Date:** October 11, 2025

## üéØ Critical Bug Fix: Message Duplication Eliminated

This release fixes a **critical bug** that caused 100% message duplication during WAL recovery. The issue was caused by dual WAL systems (old PartitionWal and new GroupCommitWal) writing to the same file paths.

### Impact
- **Before v1.3.53:** Consumers would see 2x duplicates (e.g., 20 messages when 10 were produced)
- **After v1.3.53:** 100% message recovery with ZERO duplicates ‚úÖ

## üöÄ Major Changes

### WAL Architecture Refactoring
Removed the old PartitionWal system entirely and consolidated on **GroupCommitWal** for all WAL operations:

- **Single WAL System:** Only GroupCommitWal is used (eliminates dual-write bug)
- **PostgreSQL-Style Group Commit:** Batched fsync reduces I/O overhead
- **Per-Partition Background Workers:** Efficient parallel processing
- **Zero Data Loss:** All acks modes (0, 1, -1) guaranteed durable

### Performance Improvements
- **39,200 msgs/sec** throughput at 50K message scale (acks=1)
- **12,709 msgs/sec** for 5K messages
- **20,335 msgs/sec** for 10K messages
- Full recovery in seconds even for large datasets

### Code Cleanup
- Removed obsolete PartitionWal code (~273 net lines removed)
- Removed periodic_flusher spawn calls (GroupCommitWal handles flushing internally)
- Cleaner, more maintainable codebase

## üìä Test Results

### Stress Tests (ALL PASSED)
| Messages | Throughput | Recovery | Duplicates |
|----------|------------|----------|------------|
| 5,000    | 12,709/sec | 100%     | 0          |
| 10,000   | 20,335/sec | 100%     | 0          |
| 50,000   | 39,200/sec | 100%     | 0          |

### Verification
- ‚úÖ 100% message recovery across all scales
- ‚úÖ ZERO duplicates (fixed 100% duplication bug)
- ‚úÖ Zero data loss guarantee maintained
- ‚úÖ High throughput maintained

## üîß Technical Details

### Root Cause
Both old PartitionWal and new GroupCommitWal were writing to the same file path:
```
{topic}/{partition}/wal_0_0.log
```

This caused every message to be written twice. During recovery, the WAL reader would read all records, resulting in 2x duplicates being consumed.

### Fix
1. Removed PartitionWal system entirely from WalManager
2. All append operations now route to GroupCommitWal only
3. Fixed WAL parser to stop on invalid records (length==0)
4. Updated partition discovery to scan filesystem for WAL files

### Files Changed
- `crates/chronik-wal/src/manager.rs` - Major refactor (removed PartitionWal)
- `crates/chronik-wal/src/group_commit.rs` - GroupCommitWal implementation
- `crates/chronik-server/src/wal_integration.rs` - Removed dead code
- Test infrastructure added for comprehensive recovery testing

## üéì Migration Guide

### For Existing Deployments

**No action required!** This is a transparent fix:
- GroupCommitWal uses the same file paths as before
- Recovery happens automatically on server restart
- No data migration needed
- No configuration changes required

### New Test Infrastructure

Added comprehensive recovery tests:
- `tests/test_recovery.py` - Basic recovery test (10 messages)
- `tests/test_recovery_stress.py` - Stress tests (5K, 10K, 50K)
- `tests/test_recovery_detailed.py` - Detailed duplicate detection
- `tests/debug_wal.py` - WAL file analysis tool

## üì¶ Deployment

### Docker
```bash
docker pull ghcr.io/lspecian/chronik-stream:v1.3.53
docker pull ghcr.io/lspecian/chronik-stream:latest
```

### Binary Downloads
- Linux x86_64: `chronik-server-linux-amd64.tar.gz`
- Linux ARM64: `chronik-server-linux-arm64.tar.gz`
- macOS x86_64: `chronik-server-darwin-amd64.tar.gz`
- macOS ARM64: `chronik-server-darwin-arm64.tar.gz`

## ‚ö†Ô∏è Breaking Changes

**None.** This is a bug fix release with no breaking API changes.

## üôè Acknowledgments

This fix was developed and tested using:
- Real Kafka clients (kafka-python, confluent-kafka)
- Stress testing at multiple scales (5K, 10K, 50K messages)
- Comprehensive recovery verification

---

**Full Changelog:** https://github.com/lspecian/chronik-stream/compare/v1.3.52...v1.3.53
