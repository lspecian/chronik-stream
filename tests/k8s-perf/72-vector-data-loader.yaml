apiVersion: batch/v1
kind: Job
metadata:
  name: vector-data-loader
  namespace: chronik-perf
spec:
  backoffLimit: 3
  template:
    spec:
      restartPolicy: OnFailure
      containers:
        - name: loader
          image: python:3.12-slim
          command:
            - python3
            - -c
            - |
              import json, time, random, sys, subprocess
              subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'kafka-python', '-q'])

              from kafka import KafkaProducer
              from kafka.admin import KafkaAdminClient, NewTopic

              BOOTSTRAP = 'chronik-query.chronik-perf.svc.cluster.local:9092'
              TEXT_TOPIC = 'query-bench'
              VECTOR_TOPIC = 'query-bench-vector'
              NUM_DOCS = 50000

              categories = ['compute', 'storage', 'networking', 'security', 'billing',
                            'monitoring', 'deployment', 'troubleshooting', 'api', 'database',
                            'kubernetes', 'serverless', 'ml-platform', 'edge', 'compliance']

              terms = {
                  'compute': ['instance', 'CPU', 'vCPU', 'memory', 'RAM', 'auto-scaling', 'container', 'Docker', 'GPU', 'NVIDIA', 'benchmark', 'throughput'],
                  'storage': ['S3', 'object', 'block', 'SSD', 'IOPS', 'snapshot', 'backup', 'replication', 'durability', 'Parquet', 'compression', 'tiering'],
                  'networking': ['VPC', 'subnet', 'firewall', 'load-balancer', 'CDN', 'DNS', 'TLS', 'proxy', 'gateway', 'ingress', 'latency', 'bandwidth'],
                  'security': ['encryption', 'AES-256', 'TLS-1.3', 'IAM', 'RBAC', 'OAuth2', 'SAML', 'MFA', 'HSM', 'FIPS', 'compliance', 'audit'],
                  'billing': ['pricing', 'cost', 'invoice', 'credit', 'reserved', 'spot', 'on-demand', 'budget', 'threshold', 'savings', 'forecast', 'optimization'],
                  'monitoring': ['metrics', 'dashboard', 'alert', 'Prometheus', 'Grafana', 'logs', 'traces', 'SLO', 'uptime', 'error-rate', 'anomaly', 'pager'],
                  'deployment': ['CI/CD', 'pipeline', 'Terraform', 'Helm', 'rolling-update', 'canary', 'blue-green', 'rollback', 'ArgoCD', 'GitOps', 'registry'],
                  'troubleshooting': ['timeout', '502', '503', 'connection-refused', 'OOM', 'crash', 'memory-leak', 'deadlock', 'race-condition', 'stack-trace'],
                  'api': ['REST', 'GraphQL', 'gRPC', 'rate-limit', 'pagination', 'webhook', 'OAuth', 'bearer-token', 'API-key', 'versioning', 'OpenAPI'],
                  'database': ['PostgreSQL', 'MySQL', 'MongoDB', 'Redis', 'connection-pool', 'replication', 'failover', 'sharding', 'index', 'query-plan'],
                  'kubernetes': ['pod', 'deployment', 'service', 'ingress', 'ConfigMap', 'Secret', 'PVC', 'StatefulSet', 'DaemonSet', 'CronJob', 'HPA'],
                  'serverless': ['Lambda', 'function', 'cold-start', 'warm-pool', 'event-driven', 'trigger', 'concurrency', 'timeout', 'runtime', 'layer'],
                  'ml-platform': ['PyTorch', 'TensorFlow', 'training', 'inference', 'model-registry', 'feature-store', 'pipeline', 'GPU', 'batch-prediction'],
                  'edge': ['CDN', 'edge-function', 'WebAssembly', 'cold-start', 'KV-store', 'routing', 'geolocation', 'cache', 'TTL', 'origin-shield'],
                  'compliance': ['SOC2', 'ISO-27001', 'HIPAA', 'GDPR', 'PCI-DSS', 'FedRAMP', 'data-residency', 'audit-log', 'retention', 'access-control'],
              }

              def gen_content(cat):
                  t = terms.get(cat, terms['compute'])
                  sentences = []
                  for _ in range(random.randint(3, 6)):
                      chosen = random.sample(t, min(4, len(t)))
                      templates = [
                          f"Configure {chosen[0]} with {chosen[1]} for optimal performance.",
                          f"When using {chosen[0]}, ensure {chosen[1]} is properly set up to avoid {chosen[2]} issues.",
                          f"The {chosen[0]} service supports {chosen[1]} and {chosen[2]} for enterprise workloads.",
                          f"Troubleshooting {chosen[0]}: check {chosen[1]} configuration and verify {chosen[2]} settings.",
                          f"Best practice: use {chosen[0]} with {chosen[1]} enabled. Monitor {chosen[2]} for anomalies.",
                      ]
                      sentences.append(random.choice(templates))
                  return ' '.join(sentences)

              # Step 1: Create vector topic with explicit config
              print(f"Creating vector topic '{VECTOR_TOPIC}'...")
              try:
                  admin = KafkaAdminClient(
                      bootstrap_servers=BOOTSTRAP,
                      api_version=(2, 5, 0),
                      request_timeout_ms=30000,
                  )
                  # Delete if exists
                  try:
                      admin.delete_topics([VECTOR_TOPIC])
                      time.sleep(3)
                  except: pass

                  topic = NewTopic(
                      name=VECTOR_TOPIC,
                      num_partitions=1,
                      replication_factor=1,
                      topic_configs={
                          'searchable': 'true',
                          'vector.enabled': 'true',
                          'vector.provider': 'external',
                          'vector.endpoint': 'http://embedding-adapter.chronik-perf.svc.cluster.local:8090/',
                          'vector.model': 'nomic-embed-text',
                          'vector.dimensions': '768',
                          'vector.field': 'value',
                          'vector.hnsw.metric': 'cosine',
                      }
                  )
                  admin.create_topics([topic])
                  admin.close()
                  print(f"  Created topic '{VECTOR_TOPIC}' with vector config")
              except Exception as e:
                  print(f"  Warning: Could not create topic via admin API: {e}")
                  print(f"  Will produce to auto-create (text-only)")

              # Step 2: Produce documents
              print(f"Producing {NUM_DOCS} docs to '{VECTOR_TOPIC}'...")
              producer = KafkaProducer(
                  bootstrap_servers=BOOTSTRAP,
                  value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                  api_version=(0, 10, 0),
                  linger_ms=50,
                  batch_size=65536,
              )

              start = time.time()
              success = 0
              for i in range(NUM_DOCS):
                  cat = random.choice(categories)
                  doc = {
                      'id': f'vdoc-{i:06d}',
                      'category': cat,
                      'title': f'{cat.replace("-", " ").title()} Article {i}',
                      'content': gen_content(cat),
                      'severity': random.choice(['info', 'warning', 'critical']),
                  }
                  producer.send(VECTOR_TOPIC, value=doc)
                  success += 1
                  if (i + 1) % 5000 == 0:
                      producer.flush()
                      elapsed = time.time() - start
                      rate = (i + 1) / elapsed
                      print(f"  Produced {i+1}/{NUM_DOCS} ({rate:.0f} docs/s)")

              producer.flush()
              producer.close()
              elapsed = time.time() - start
              print(f"Done: {success}/{NUM_DOCS} docs in {elapsed:.1f}s ({success/elapsed:.0f} docs/s)")

              # Step 3: Also add more docs to text-only topic if it has fewer than 100K
              print(f"\nProducing additional docs to text topic '{TEXT_TOPIC}'...")
              producer = KafkaProducer(
                  bootstrap_servers=BOOTSTRAP,
                  value_serializer=lambda v: json.dumps(v).encode('utf-8'),
                  api_version=(0, 10, 0),
                  linger_ms=50,
                  batch_size=65536,
              )

              start = time.time()
              success2 = 0
              for i in range(50000):
                  cat = random.choice(categories)
                  doc = {
                      'id': f'doc-extra-{i:06d}',
                      'category': cat,
                      'title': f'{cat.replace("-", " ").title()} Extended Article {i}',
                      'content': gen_content(cat),
                      'severity': random.choice(['info', 'warning', 'critical']),
                  }
                  producer.send(TEXT_TOPIC, value=doc)
                  success2 += 1
                  if (i + 1) % 5000 == 0:
                      producer.flush()

              producer.flush()
              producer.close()
              elapsed = time.time() - start
              print(f"Text topic: {success2} additional docs in {elapsed:.1f}s")
              print(f"\nTotal: {success + success2} docs across both topics")
          resources:
            requests:
              cpu: "1"
              memory: "512Mi"
            limits:
              cpu: "2"
              memory: "1Gi"
