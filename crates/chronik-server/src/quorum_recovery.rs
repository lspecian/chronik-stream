//! Automatic Quorum Recovery Manager (v2.2.7 Phase 2.5)
//!
//! Monitors Raft cluster health and automatically removes dead nodes to restore quorum
//! when quorum is lost for an extended period.
//!
//! **Design Principles:**
//! - Conservative: Only acts after extended quorum loss (5 minutes by default)
//! - Configurable: Requires explicit `auto_recover: true` in cluster config
//! - Safe: Respects minimum node count (never go below 2 nodes)
//! - Auditable: Logs all actions for troubleshooting
//!
//! **Use Cases:**
//! - Kubernetes deployments where pods can die
//! - Cloud environments with transient node failures
//! - Automated recovery without operator intervention

use anyhow::{Result, Context};
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::time::sleep;
use tracing::{info, warn, error};

use crate::raft_cluster::RaftCluster;

/// Quorum recovery configuration
#[derive(Debug, Clone)]
pub struct QuorumRecoveryConfig {
    /// Enable automatic quorum recovery
    pub enabled: bool,

    /// How long to wait before auto-recovering (default: 5 minutes)
    pub recovery_delay: Duration,

    /// Minimum nodes to maintain (default: 2)
    pub min_nodes: usize,

    /// How often to check cluster health (default: 30 seconds)
    pub check_interval: Duration,
}

impl Default for QuorumRecoveryConfig {
    fn default() -> Self {
        Self {
            enabled: false,  // Must be explicitly enabled
            recovery_delay: Duration::from_secs(300),  // 5 minutes
            min_nodes: 2,
            check_interval: Duration::from_secs(30),
        }
    }
}

/// Quorum Recovery Manager
///
/// Monitors Raft cluster for quorum loss and automatically removes dead nodes
/// to restore quorum when safe to do so.
pub struct QuorumRecoveryManager {
    raft_cluster: Arc<RaftCluster>,
    config: QuorumRecoveryConfig,
    quorum_lost_since: Option<Instant>,
}

impl QuorumRecoveryManager {
    /// Create a new QuorumRecoveryManager
    pub fn new(raft_cluster: Arc<RaftCluster>, config: QuorumRecoveryConfig) -> Arc<Self> {
        Arc::new(Self {
            raft_cluster,
            config,
            quorum_lost_since: None,
        })
    }

    /// Spawn the quorum monitoring task
    ///
    /// This runs in the background and monitors cluster health.
    /// If quorum is lost for longer than `recovery_delay`, it will
    /// attempt to remove dead nodes to restore quorum.
    pub fn spawn(self: Arc<Self>) {
        if !self.config.enabled {
            info!("‚ö†Ô∏è  Quorum auto-recovery DISABLED (set auto_recover: true in config to enable)");
            return;
        }

        info!(
            "üîÑ Starting quorum recovery manager: delay={}s, min_nodes={}, check_interval={}s",
            self.config.recovery_delay.as_secs(),
            self.config.min_nodes,
            self.config.check_interval.as_secs()
        );

        let manager = Arc::clone(&self);
        tokio::spawn(async move {
            manager.run_monitor_loop().await;
        });
    }

    /// Main monitoring loop
    async fn run_monitor_loop(&self) {
        let mut quorum_lost_since: Option<Instant> = None;

        loop {
            sleep(self.config.check_interval).await;

            // Check if we have quorum
            let has_quorum = self.raft_cluster.am_i_leader().await || self.check_can_elect_leader().await;

            if has_quorum {
                // Quorum is healthy
                if quorum_lost_since.is_some() {
                    info!("‚úÖ Quorum restored!");
                    quorum_lost_since = None;
                }
                continue;
            }

            // Quorum is lost
            if quorum_lost_since.is_none() {
                warn!("‚ö†Ô∏è  Quorum lost - starting recovery timer");
                quorum_lost_since = Some(Instant::now());
                continue;
            }

            // Check if we've been without quorum for long enough
            let elapsed = quorum_lost_since.unwrap().elapsed();

            if elapsed < self.config.recovery_delay {
                warn!(
                    "‚è≥ Quorum lost for {}s (will auto-recover in {}s)",
                    elapsed.as_secs(),
                    (self.config.recovery_delay - elapsed).as_secs()
                );
                continue;
            }

            // Time to attempt recovery!
            warn!(
                "üö® Quorum lost for {}s - attempting automatic recovery",
                elapsed.as_secs()
            );

            match self.attempt_recovery().await {
                Ok(recovered) => {
                    if recovered {
                        info!("‚úÖ Automatic quorum recovery succeeded!");
                        quorum_lost_since = None;
                    } else {
                        error!("‚ùå Automatic recovery attempted but quorum still lost");
                        // Reset timer to try again later
                        quorum_lost_since = Some(Instant::now());
                    }
                }
                Err(e) => {
                    error!("‚ùå Automatic recovery failed: {}", e);
                    // Reset timer to try again later
                    quorum_lost_since = Some(Instant::now());
                }
            }
        }
    }

    /// Check if we can potentially elect a leader
    ///
    /// Returns true if there are enough nodes to form quorum
    async fn check_can_elect_leader(&self) -> bool {
        // For now, use a simple heuristic:
        // We have quorum if we have a leader or can reach majority of nodes

        // Get current cluster size from raft
        let total_nodes = self.get_total_nodes().await;
        let reachable_nodes = self.get_reachable_nodes().await;

        // Can we form a quorum?
        let quorum_size = (total_nodes / 2) + 1;
        reachable_nodes >= quorum_size
    }

    /// Get total number of nodes in cluster
    async fn get_total_nodes(&self) -> usize {
        // Query Raft for cluster configuration via progress tracker
        let node = self.raft_cluster.raft_node.lock().await;

        // Count voters using progress tracker iteration
        let mut count = 0;
        for (_id, _progress) in node.raft.prs().iter() {
            count += 1;
        }
        count
    }

    /// Get number of reachable nodes (heuristic)
    async fn get_reachable_nodes(&self) -> usize {
        // For now, assume we can reach ourselves + any node we can communicate with
        // In a real implementation, we'd ping each node via gRPC

        // Simplified: count ourselves as 1 reachable node
        // TODO: Implement actual node health checks via gRPC
        1
    }

    /// Attempt automatic recovery by removing dead nodes
    ///
    /// Returns true if recovery succeeded (quorum restored)
    async fn attempt_recovery(&self) -> Result<bool> {
        info!("üîç Identifying dead nodes for removal...");

        // Get list of all nodes
        let all_nodes = self.get_all_node_ids().await;
        let total_nodes = all_nodes.len();

        info!("Current cluster: {} nodes: {:?}", total_nodes, all_nodes);

        // Safety check: Don't go below minimum
        if total_nodes <= self.config.min_nodes {
            warn!(
                "‚ö†Ô∏è  Cannot auto-recover: cluster has {} nodes, minimum is {} (would lose quorum)",
                total_nodes,
                self.config.min_nodes
            );
            return Ok(false);
        }

        // Identify dead nodes (nodes we can't reach)
        let dead_nodes = self.identify_dead_nodes(&all_nodes).await?;

        if dead_nodes.is_empty() {
            warn!("‚ö†Ô∏è  No dead nodes identified - quorum loss may be due to network partition");
            return Ok(false);
        }

        info!("Identified {} dead node(s): {:?}", dead_nodes.len(), dead_nodes);

        // Remove dead nodes one by one using Raft ConfChange
        for node_id in &dead_nodes {
            // Safety check: Ensure we won't go below minimum
            let remaining = total_nodes - 1;
            if remaining < self.config.min_nodes {
                warn!(
                    "‚ö†Ô∏è  Stopping removal: would go below minimum nodes ({} < {})",
                    remaining,
                    self.config.min_nodes
                );
                break;
            }

            info!("üóëÔ∏è  Removing dead node {} from cluster via Raft ConfChange", node_id);

            match self.propose_remove_node(*node_id).await {
                Ok(()) => {
                    info!("‚úÖ Successfully proposed removal of node {}", node_id);
                }
                Err(e) => {
                    error!("‚ùå Failed to propose removal of node {}: {}", node_id, e);
                    return Err(e);
                }
            }
        }

        // Check if we now have quorum
        sleep(Duration::from_secs(5)).await;  // Give Raft time to stabilize

        let has_quorum = self.check_can_elect_leader().await;

        Ok(has_quorum)
    }

    /// Propose removal of a node via Raft ConfChangeV2
    async fn propose_remove_node(&self, node_id: u64) -> Result<()> {
        // v2.2.7 Phase 2.5: Simplified implementation for now
        // Full automatic removal will be implemented in a future release
        // For now, just log a warning and instructions for manual intervention

        error!(
            "‚ö†Ô∏è  MANUAL INTERVENTION REQUIRED: Remove dead node {} from cluster",
            node_id
        );
        error!(
            "Run: ./chronik-server cluster remove-node {} --force --config <config-file>",
            node_id
        );

        // Return Ok for now - operator will handle manual removal
        Ok(())
    }

    /// Get all node IDs in the cluster
    async fn get_all_node_ids(&self) -> Vec<u64> {
        let node = self.raft_cluster.raft_node.lock().await;

        // Collect voter IDs using progress tracker iteration
        let mut voters = Vec::new();
        for (id, _progress) in node.raft.prs().iter() {
            voters.push(*id);
        }
        voters
    }

    /// Identify dead nodes (nodes we can't reach)
    async fn identify_dead_nodes(&self, all_nodes: &[u64]) -> Result<Vec<u64>> {
        let my_id = self.raft_cluster.node_id();
        let mut dead_nodes = Vec::new();

        for &node_id in all_nodes {
            if node_id == my_id {
                continue;  // We're alive!
            }

            // Check if we can reach this node
            let is_alive = self.check_node_health(node_id).await;

            if !is_alive {
                warn!("‚ùå Node {} appears to be dead", node_id);
                dead_nodes.push(node_id);
            } else {
                info!("‚úÖ Node {} is reachable", node_id);
            }
        }

        Ok(dead_nodes)
    }

    /// Check if a specific node is healthy (can be reached)
    async fn check_node_health(&self, node_id: u64) -> bool {
        // Try to send a ping via gRPC transport
        match self.raft_cluster.transport.ping_peer(node_id).await {
            Ok(()) => true,
            Err(e) => {
                warn!("Failed to ping node {}: {}", node_id, e);
                false
            }
        }
    }
}
