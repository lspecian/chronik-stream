//! Kafka protocol handler for the ingest server.
//! 
//! This module provides a wrapper around the chronik-protocol ProtocolHandler
//! with additional ingest-specific functionality.

use std::sync::Arc;
use std::collections::HashSet;
use chronik_common::{Result, Error};
use chronik_common::metadata::traits::MetadataStore;
use chronik_protocol::{ProtocolHandler, handler::Response, parser::{parse_request_header, ApiKey, write_response_header, ResponseHeader}, error_codes};
use chronik_storage::{SegmentReader, ObjectStoreTrait};
use crate::produce_handler::ProduceHandler;
use crate::consumer_group::GroupManager;
use crate::fetch_handler::FetchHandler;
use crate::wal_integration::WalProduceHandler;
use bytes::{Bytes, BytesMut, BufMut, Buf};
use tokio::sync::RwLock;
use tracing::{debug, instrument};

/// Kafka protocol handler with ingest-specific extensions
pub struct KafkaProtocolHandler {
    /// Core protocol handler from chronik-protocol
    protocol_handler: ProtocolHandler,
    /// Produce handler for writing data
    produce_handler: Arc<ProduceHandler>,
    /// WAL handler for durability (MANDATORY - no longer optional)
    wal_handler: Arc<WalProduceHandler>,
    /// Segment reader for fetch operations
    segment_reader: Arc<SegmentReader>,
    /// Metadata store
    metadata_store: Arc<dyn MetadataStore>,
    /// Consumer group manager
    group_manager: Arc<GroupManager>,
    /// Fetch handler for reading data
    fetch_handler: Arc<FetchHandler>,
    /// Node ID
    node_id: i32,
    /// Host address
    host: String,
    /// Port number
    port: i32,
    /// Expected topics tracker for v0 metadata compatibility
    expected_topics: Arc<RwLock<HashSet<String>>>,
    /// Default number of partitions for auto-created topics
    default_num_partitions: u32,
}

impl KafkaProtocolHandler {
    /// Create a new Kafka protocol handler with WAL (MANDATORY)
    /// WAL is now required for all Chronik Stream instances - no optional paths
    pub async fn new(
        produce_handler: Arc<ProduceHandler>,
        segment_reader: Arc<SegmentReader>,
        metadata_store: Arc<dyn MetadataStore>,
        object_store: Arc<dyn ObjectStoreTrait>,
        fetch_handler: Arc<FetchHandler>,
        wal_handler: Arc<WalProduceHandler>,  // WAL is MANDATORY, not optional
        node_id: i32,
        host: String,
        port: i32,
        default_num_partitions: u32,
    ) -> Result<Self> {
        let group_manager = Arc::new(GroupManager::new(metadata_store.clone()));
        group_manager.clone().start_expiration_checker();
        
        Ok(Self {
            protocol_handler: ProtocolHandler::with_full_config(
                metadata_store.clone(),
                node_id,
                host.clone(),
                port
            ),
            produce_handler,
            wal_handler,
            segment_reader,
            metadata_store,
            group_manager,
            fetch_handler,
            node_id,
            host: host.clone(),
            port,
            expected_topics: Arc::new(RwLock::new(HashSet::new())),
            default_num_partitions,
        })
    }

    /// Get reference to the produce handler for shutdown
    pub fn get_produce_handler(&self) -> &Arc<ProduceHandler> {
        &self.produce_handler
    }

    /// Get reference to the WAL produce handler for shutdown
    pub fn get_wal_handler(&self) -> &Arc<WalProduceHandler> {
        &self.wal_handler
    }

    /// Handle a Kafka protocol request
    #[instrument(skip(self, request_bytes))]
    pub async fn handle_request(&self, request_bytes: &[u8]) -> Result<Response> {
        // Helper to detect if we should pre-create a test topic for kafka-python clients
        self.infer_expected_topics_from_context().await;
        debug!("Handling request of {} bytes", request_bytes.len());
        
        // Log first few bytes to identify request type
        if request_bytes.len() >= 4 {
            let api_key = i16::from_be_bytes([request_bytes[0], request_bytes[1]]);
            let api_version = i16::from_be_bytes([request_bytes[2], request_bytes[3]]);
            tracing::info!("Request: API key={}, version={}", api_key, api_version);
        }
        
        
        // Parse the request header to determine which API is being called
        let mut buf = bytes::Bytes::from(request_bytes.to_vec());
        let header = parse_request_header(&mut buf)?;

        // Save a copy of the buffer for metadata processing
        let _buf_copy = buf.clone();

        // Route to specific handlers for certain API keys
        // produce and fetch are special-cased because they need access to our storage layer
        // we should intercept and handle them directly
        match header.api_key {
            ApiKey::Metadata => {
                // Parse the metadata request to get requested topics for auto-creation
                use chronik_protocol::parser::Decoder;
                let flexible = header.api_version >= 9;

                // Clone the buffer for parsing (so original buf remains unchanged for handle_metadata)
                let mut buf_for_parsing = buf.clone();
                let mut decoder = Decoder::new(&mut buf_for_parsing);

                // Parse topics array
                let topics = if header.api_version >= 1 {
                    let topic_count = if flexible {
                        // Compact array
                        let count = decoder.read_unsigned_varint()? as i32;
                        if count == 0 {
                            -1  // Null array
                        } else {
                            count - 1  // Compact arrays use +1 encoding
                        }
                    } else {
                        decoder.read_i32()?
                    };

                    if topic_count < 0 {
                        None // All topics
                    } else {
                        let mut topic_names = Vec::with_capacity(topic_count as usize);
                        for _ in 0..topic_count {
                            // v10+ includes topic_id (UUID) before name
                            if header.api_version >= 10 {
                                // Skip the 16-byte UUID
                                for _ in 0..16 {
                                    decoder.read_i8()?;
                                }
                            }

                            let name = if flexible {
                                decoder.read_compact_string()?
                            } else {
                                decoder.read_string()?
                            };

                            if let Some(name) = name {
                                topic_names.push(name);
                            }

                            if flexible {
                                // Skip tagged fields for each topic
                                let tagged_count = decoder.read_unsigned_varint()?;
                                for _ in 0..tagged_count {
                                    let _tag_id = decoder.read_unsigned_varint()?;
                                    let tag_size = decoder.read_unsigned_varint()? as usize;
                                    decoder.advance(tag_size)?;
                                }
                            }
                        }
                        Some(topic_names)
                    }
                } else {
                    // v0 gets all topics - this is where we need to help kafka-python
                    None
                };

                let allow_auto_topic_creation = if header.api_version >= 4 {
                    decoder.read_bool()?
                } else {
                    true
                };

                // Auto-create requested topics if enabled
                if allow_auto_topic_creation {
                    if let Some(requested_topics) = &topics {
                        if !requested_topics.is_empty() {
                            tracing::info!("Metadata request for topics: {:?}, auto-creating if needed", requested_topics);
                            self.track_expected_topics(requested_topics).await;
                            if let Err(e) = self.auto_create_topics(requested_topics).await {
                                tracing::warn!("Failed to auto-create topics on metadata: {:?}", e);
                                // Continue anyway - metadata handler will return UNKNOWN_TOPIC_OR_PARTITION
                            }
                        }
                    } else if header.api_version == 0 {
                        // Special handling for v0: auto-create any expected topics
                        let expected = self.expected_topics.read().await.clone();
                        if !expected.is_empty() {
                            let topics_vec: Vec<String> = expected.into_iter().collect();
                            tracing::info!("Metadata v0 request - auto-creating expected topics: {:?}", topics_vec);
                            if let Err(e) = self.auto_create_topics(&topics_vec).await {
                                tracing::warn!("Failed to auto-create expected topics: {:?}", e);
                            }
                        }
                    }
                }

                // Now delegate to protocol handler for the actual metadata response
                // Call handle_metadata directly with header and body buffer
                // NOTE: No need to skip extra bytes - header parsing now correctly handles Java vs librdkafka differences
                self.protocol_handler.handle_metadata(header, &mut buf).await
            }
            ApiKey::Produce => {
                tracing::debug!("Produce handler called: version={}, correlation_id={}", header.api_version, header.correlation_id);

                // Parse the produce request
                let request = self.protocol_handler.parse_produce_request(&header, &mut buf)?;

                tracing::debug!("Produce request parsed: topics_count={}", request.topics.len());

                // Auto-create topics if they don't exist
                let topic_names: Vec<String> = request.topics.iter()
                    .map(|t| t.name.clone())
                    .collect();

                if !topic_names.is_empty() {
                    tracing::info!("Produce request for topics: {:?}", topic_names);

                    // Check which topics don't exist and create them
                    if let Err(e) = self.auto_create_topics(&topic_names).await {
                        tracing::warn!("Failed to auto-create topics on produce: {:?}", e);
                        // Continue anyway - the produce might still work
                    }
                }

                // WAL is mandatory - all produce requests MUST go through WAL
                // There is no fallback path - WAL is the only durability mechanism
                let response = self.wal_handler.handle_produce(request, header.correlation_id).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                eprintln!("CRITICAL: About to call encode_produce_response with version {}", header.api_version);
                self.protocol_handler.encode_produce_response(&mut body_buf, &response, header.api_version)?;
                
                // Create response header
                let response_header = ResponseHeader {
                    correlation_id: header.correlation_id,
                };
                
                // Write response header
                let mut header_buf = BytesMut::new();
                write_response_header(&mut header_buf, &response_header);
                
                // Combine header and body
                let mut final_buf = BytesMut::new();
                final_buf.extend_from_slice(&header_buf);
                final_buf.extend_from_slice(&body_buf);
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 9,  // v9+ uses flexible/compact encoding
                    api_key: ApiKey::Produce,
                    throttle_time_ms: None,
                })
            }
            ApiKey::ListOffsets => {
                // Parse the ListOffsets request manually
                use chronik_protocol::list_offsets_types::{
                    ListOffsetsRequest, ListOffsetsRequestTopic, ListOffsetsRequestPartition,
                    ListOffsetsResponse, ListOffsetsResponseTopic, ListOffsetsResponsePartition
                };
                use chronik_protocol::parser::Decoder;

                const LATEST_TIMESTAMP: i64 = -1;
                const EARLIEST_TIMESTAMP: i64 = -2;

                tracing::info!("ListOffsets request received, API version: {}", header.api_version);

                let is_flexible = header.api_version >= 6;
                // Note: No extra bytes to skip - header parsing now correctly handles Java client_id

                let mut decoder = Decoder::new(&mut buf);

                // Parse ListOffsets request
                let _replica_id = decoder.read_i32()?;
                let _isolation_level = if header.api_version >= 2 {
                    decoder.read_i8()?
                } else {
                    0
                };

                // Topics array - use compact array for v6+
                let topics_count = if is_flexible {
                    let count = decoder.read_unsigned_varint()? as i32;
                    if count == 0 { 0 } else { count - 1 } // Compact array encoding
                } else {
                    decoder.read_i32()?
                };

                // Safety check to prevent capacity overflow panic
                if topics_count < 0 || topics_count > 10000 {
                    return Err(Error::Protocol(format!("Invalid topics count: {}", topics_count)));
                }
                let mut topics = Vec::with_capacity(topics_count as usize);

                for _ in 0..topics_count {
                    // Topic name - use compact string for v6+
                    let topic_name = if is_flexible {
                        decoder.read_compact_string()?
                            .ok_or_else(|| Error::Protocol("Topic name cannot be null".into()))?
                    } else {
                        decoder.read_string()?
                            .ok_or_else(|| Error::Protocol("Topic name cannot be null".into()))?
                    };

                    // Partitions array - use compact array for v6+
                    let partitions_count = if is_flexible {
                        let count = decoder.read_unsigned_varint()? as i32;
                        if count == 0 { 0 } else { count - 1 }
                    } else {
                        decoder.read_i32()?
                    };

                    // Safety check
                    if partitions_count < 0 || partitions_count > 10000 {
                        return Err(Error::Protocol(format!("Invalid partitions count: {}", partitions_count)));
                    }
                    let mut partitions = Vec::with_capacity(partitions_count as usize);

                    for _ in 0..partitions_count {
                        let partition_index = decoder.read_i32()?;
                        let current_leader_epoch = if header.api_version >= 4 {
                            decoder.read_i32()?
                        } else {
                            -1
                        };
                        let timestamp = decoder.read_i64()?;

                        // Skip tagged fields for each partition in flexible versions
                        if is_flexible {
                            let tagged_count = decoder.read_unsigned_varint()?;
                            for _ in 0..tagged_count {
                                let _tag_id = decoder.read_unsigned_varint()?;
                                let tag_size = decoder.read_unsigned_varint()? as usize;
                                decoder.advance(tag_size)?;
                            }
                        }

                        partitions.push(ListOffsetsRequestPartition {
                            partition_index,
                            current_leader_epoch,
                            timestamp,
                        });
                    }

                    // Skip tagged fields for each topic in flexible versions
                    if is_flexible {
                        let tagged_count = decoder.read_unsigned_varint()?;
                        for _ in 0..tagged_count {
                            let _tag_id = decoder.read_unsigned_varint()?;
                            let tag_size = decoder.read_unsigned_varint()? as usize;
                            decoder.advance(tag_size)?;
                        }
                    }

                    topics.push(ListOffsetsRequestTopic {
                        name: topic_name,
                        partitions,
                    });
                }

                // Skip request-level tagged fields for flexible versions
                if is_flexible {
                    let tagged_count = decoder.read_unsigned_varint()?;
                    for _ in 0..tagged_count {
                        let _tag_id = decoder.read_unsigned_varint()?;
                        let tag_size = decoder.read_unsigned_varint()? as usize;
                        decoder.advance(tag_size)?;
                    }
                }

                // Build response with real offsets
                let mut response_topics = Vec::new();

                for topic in topics {
                    let mut response_partitions = Vec::new();

                    for partition in topic.partitions {
                        tracing::info!("ListOffsets: Processing topic {} partition {} with timestamp {}",
                            topic.name, partition.partition_index, partition.timestamp);

                        let (offset, timestamp_found) = match partition.timestamp {
                            LATEST_TIMESTAMP => {
                                // Get high watermark from ProduceHandler (includes in-memory messages)
                                let in_memory_hw = self.produce_handler
                                    .get_partition_high_watermark(&topic.name, partition.partition_index)
                                    .await;

                                // Also check segments for persisted data
                                let segment_hw = match self.metadata_store.list_segments(&topic.name, Some(partition.partition_index as u32)).await {
                                    Ok(segments) => {
                                        segments.iter()
                                            .map(|s| s.end_offset + 1)
                                            .max()
                                            .unwrap_or(0)
                                    }
                                    Err(_) => 0
                                };

                                // Use the maximum of in-memory and segment high watermarks
                                let high_watermark = in_memory_hw.max(segment_hw);

                                tracing::info!("ListOffsets: Returning high watermark {} for {}-{} (in-memory: {}, segments: {})",
                                    high_watermark, topic.name, partition.partition_index, in_memory_hw, segment_hw);

                                (high_watermark, std::time::SystemTime::now()
                                    .duration_since(std::time::UNIX_EPOCH)
                                    .unwrap()
                                    .as_millis() as i64)
                            }
                            EARLIEST_TIMESTAMP => {
                                // Return the earliest offset (always 0 for now)
                                tracing::info!("ListOffsets: Returning earliest offset 0 for {}-{}",
                                    topic.name, partition.partition_index);
                                (0, std::time::SystemTime::now()
                                    .duration_since(std::time::UNIX_EPOCH)
                                    .unwrap()
                                    .as_millis() as i64 - 86400000) // 1 day ago
                            }
                            ts if ts >= 0 => {
                                // Return offset for specific timestamp (dummy implementation)
                                (500, ts)
                            }
                            _ => {
                                // Invalid timestamp
                                (0, 0)
                            }
                        };

                        let response_part = ListOffsetsResponsePartition {
                            partition_index: partition.partition_index,
                            error_code: error_codes::NONE,
                            timestamp: if header.api_version >= 1 { timestamp_found } else { -1 },
                            offset,
                            leader_epoch: if header.api_version >= 4 { 0 } else { -1 },
                        };

                        tracing::info!("ListOffsets: Response for {}-{}: offset={}, timestamp={}, error_code={}",
                            topic.name, partition.partition_index, offset,
                            if header.api_version >= 1 { timestamp_found } else { -1 },
                            error_codes::NONE);

                        response_partitions.push(response_part);
                    }

                    response_topics.push(ListOffsetsResponseTopic {
                        name: topic.name,
                        partitions: response_partitions,
                    });
                }

                let response = ListOffsetsResponse {
                    throttle_time_ms: 0,
                    topics: response_topics,
                };

                // Encode response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_list_offsets_response(&mut body_buf, &response, header.api_version)?;

                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 6,
                    api_key: ApiKey::ListOffsets,
                    throttle_time_ms: None,
                })
            }
            ApiKey::Fetch => {
                // Parse the fetch request
                let request = self.protocol_handler.parse_fetch_request(&header, &mut buf)?;
                
                // Use our fetch handler to process the request
                let response = self.fetch_handler.handle_fetch(request, header.correlation_id).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_fetch_response(&mut body_buf, &response, header.api_version)?;
                
                // Create response header
                let response_header = ResponseHeader {
                    correlation_id: header.correlation_id,
                };
                
                // Write response header
                let mut header_buf = BytesMut::new();
                write_response_header(&mut header_buf, &response_header);
                
                // Combine header and body
                let mut final_buf = BytesMut::new();
                final_buf.extend_from_slice(&header_buf);
                final_buf.extend_from_slice(&body_buf);
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 12, // Fetch uses flexible from v12+ (not v11)
                    api_key: ApiKey::Fetch,
                    throttle_time_ms: None,
                })
            }
            ApiKey::JoinGroup => {
                debug!("Processing JoinGroup request");
                // Parse the join group request
                let request = self.protocol_handler.parse_join_group_request(&header, &mut buf)?;
                
                // Handle the join group request
                let response = self.group_manager.handle_join_group(request).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_join_group_response(&mut body_buf, &response, header.api_version)?;
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 6, // JoinGroup uses flexible from v6+
                    api_key: ApiKey::JoinGroup,
                    throttle_time_ms: None,
                })
            }
            ApiKey::SyncGroup => {
                debug!("Processing SyncGroup request");
                // Parse the sync group request
                let request = self.protocol_handler.parse_sync_group_request(&header, &mut buf)?;
                
                // Handle the sync group request
                let response = self.group_manager.handle_sync_group(request).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_sync_group_response(&mut body_buf, &response, header.api_version)?;
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 4, // SyncGroup uses flexible from v4+
                    api_key: ApiKey::SyncGroup,
                    throttle_time_ms: None,
                })
            }
            ApiKey::Heartbeat => {
                debug!("Processing Heartbeat request");
                // Parse the heartbeat request
                let request = self.protocol_handler.parse_heartbeat_request(&header, &mut buf)?;
                
                // Handle the heartbeat request
                let response = self.group_manager.handle_heartbeat(request).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_heartbeat_response(&mut body_buf, &response, header.api_version)?;
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 4, // Heartbeat uses flexible from v4+
                    api_key: ApiKey::Heartbeat,
                    throttle_time_ms: None,
                })
            }
            ApiKey::LeaveGroup => {
                debug!("Processing LeaveGroup request");
                // Parse the leave group request
                let request = self.protocol_handler.parse_leave_group_request(&header, &mut buf)?;
                
                // Handle the leave group request
                let response = self.group_manager.handle_leave_group(request).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_leave_group_response(&mut body_buf, &response, header.api_version)?;
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 4, // LeaveGroup uses flexible from v4+
                    api_key: ApiKey::LeaveGroup,
                    throttle_time_ms: None,
                })
            }
            ApiKey::OffsetCommit => {
                debug!("Processing OffsetCommit request");
                // Parse the offset commit request
                let request = self.protocol_handler.parse_offset_commit_request(&header, &mut buf)?;
                
                // Handle the offset commit request
                let response = self.group_manager.handle_offset_commit(request).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_offset_commit_response(&mut body_buf, &response, header.api_version)?;
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 8, // OffsetCommit uses flexible from v8+
                    api_key: ApiKey::OffsetCommit,
                    throttle_time_ms: None,
                })
            }
            ApiKey::OffsetFetch => {
                debug!("Processing OffsetFetch request");
                // Parse the offset fetch request
                let request = self.protocol_handler.parse_offset_fetch_request(&header, &mut buf)?;
                
                // Handle the offset fetch request
                let response = self.group_manager.handle_offset_fetch(request).await?;
                
                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_offset_fetch_response(&mut body_buf, &response, header.api_version)?;
                
                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 6, // OffsetFetch uses flexible from v6+
                    api_key: ApiKey::OffsetFetch,
                    throttle_time_ms: None,
                })
            }
            ApiKey::FindCoordinator => {
                tracing::info!("Processing FindCoordinator v{} request", header.api_version);
                tracing::info!("FindCoordinator request buffer: {} bytes: {:?}", buf.len(), &buf[..std::cmp::min(buf.len(), 64)]);

                // Parse the find coordinator request
                let request = self.protocol_handler.parse_find_coordinator_request(&header, &mut buf)?;
                tracing::info!("FindCoordinator parsed: key='{}', key_type={}", request.key, request.key_type);

                // Handle the find coordinator request
                let response = self.group_manager.handle_find_coordinator(request, &self.host, self.port)?;
                tracing::info!("FindCoordinator response: node_id={}, host={}:{}, coordinators.len()={}",
                    response.node_id, response.host, response.port, response.coordinators.len());

                // Encode the response
                let mut body_buf = BytesMut::new();
                self.protocol_handler.encode_find_coordinator_response(&mut body_buf, &response, header.api_version)?;
                tracing::debug!("FindCoordinator response encoded: {} bytes: {:?}", body_buf.len(), &body_buf[..std::cmp::min(body_buf.len(), 64)]);

                Ok(Response {
                    header: ResponseHeader {
                        correlation_id: header.correlation_id,
                    },
                    body: body_buf.freeze(),
                    is_flexible: header.api_version >= 3, // FindCoordinator uses flexible from v3+
                    api_key: ApiKey::FindCoordinator,
                    throttle_time_ms: None,
                })
            }
            ApiKey::CreateTopics => {
                tracing::info!("Processing CreateTopics v{} request", header.api_version);

                // First, let protocol handler create the topics in metadata store
                let response = self.protocol_handler.handle_request(request_bytes.clone()).await?;

                // Phase 3: Initialize Raft partition metadata for created topics
                // Parse the request to extract topic names and partition counts
                use chronik_protocol::create_topics_types::CreateTopicsRequest;
                use chronik_protocol::parser::Decoder;

                let mut decoder = Decoder::new(&mut buf);
                let use_compact = header.api_version >= 5;

                // Parse topic count
                let topic_count = if use_compact {
                    let compact_len = decoder.read_unsigned_varint()?;
                    if compact_len > 0 { (compact_len - 1) as usize } else { 0 }
                } else {
                    let len = decoder.read_i32()?;
                    if len >= 0 { len as usize } else { 0 }
                };

                // Parse each topic and initialize Raft partition metadata
                for _ in 0..topic_count {
                    // Topic name
                    let topic_name = if use_compact {
                        decoder.read_compact_string()?.unwrap_or_default()
                    } else {
                        decoder.read_string()?.unwrap_or_default()
                    };

                    // Number of partitions
                    let num_partitions = decoder.read_i32()?;

                    if num_partitions > 0 {
                        // Initialize Raft partition metadata asynchronously
                        // This proposes AssignPartition, SetPartitionLeader, and UpdateISR commands
                        if let Err(e) = self.produce_handler.initialize_raft_partitions(
                            &topic_name,
                            num_partitions as u32
                        ).await {
                            tracing::warn!("Failed to initialize Raft partition metadata for '{}': {:?}",
                                         topic_name, e);
                            // Continue anyway - topic is already created in metadata store
                        } else {
                            tracing::info!("âœ“ Phase 3: Initialized Raft partition metadata for topic '{}' ({} partitions)",
                                         topic_name, num_partitions);
                        }
                    }

                    // Skip remaining fields (we only need topic name and partition count)
                    // This is a simplified parse - full parsing is done by protocol handler
                    // We just need to extract the topic names to initialize Raft metadata
                    break; // For now, handle first topic only (can extend later)
                }

                Ok(response)
            }
            _ => {
                // For all other API calls, delegate to the protocol handler
                tracing::info!("Delegating API {:?} v{} to protocol_handler", header.api_key, header.api_version);
                self.protocol_handler.handle_request(request_bytes).await
            }
        }
    }

    /// Track topics that clients are likely interested in
    async fn track_expected_topics(&self, topic_names: &[String]) {
        let mut expected = self.expected_topics.write().await;
        for topic in topic_names {
            expected.insert(topic.clone());
        }
        tracing::debug!("Expected topics now includes: {:?}", expected);
    }

    /// Infer expected topics from context (for kafka-python compatibility)
    async fn infer_expected_topics_from_context(&self) {
        // Check if we already have expected topics
        let expected = self.expected_topics.read().await;
        if !expected.is_empty() {
            return;
        }
        drop(expected);

        // For now, we'll pre-populate common test topics that kafka-python might use
        // This is a workaround for v0 metadata clients that can't specify topics
        let common_test_topics = vec![
            "test-topic".to_string(),
            "test".to_string(),
        ];

        let mut expected = self.expected_topics.write().await;
        for topic in common_test_topics {
            expected.insert(topic);
        }
        tracing::debug!("Pre-populated expected topics for v0 compatibility: {:?}", expected);
    }

    /// Auto-create topics that don't exist
    ///
    /// Delegates to ProduceHandler::auto_create_topic() which handles:
    /// - Topic metadata creation
    /// - Partition assignments
    /// - Raft replica creation (if Raft is enabled)
    /// - Validation and deduplication
    async fn auto_create_topics(&self, topic_names: &[String]) -> Result<()> {
        // Get list of existing topics
        let existing_topics = self.metadata_store.list_topics().await
            .map_err(|e| Error::Internal(format!("Failed to list topics: {:?}", e)))?;

        let existing_topic_names: std::collections::HashSet<String> =
            existing_topics.into_iter().map(|t| t.name).collect();

        // Find topics that don't exist
        let topics_to_create: Vec<&String> = topic_names
            .iter()
            .filter(|t| !existing_topic_names.contains(*t))
            .collect();

        if !topics_to_create.is_empty() {
            tracing::info!("Auto-creating {} topics via ProduceHandler (ensures Raft replica creation): {:?}",
                topics_to_create.len(), topics_to_create);

            for topic_name in topics_to_create {
                // Delegate to ProduceHandler which handles:
                // - Topic creation with default config
                // - Partition assignments
                // - Raft replica creation (if enabled)
                // - Proper error handling and retries
                match self.produce_handler.auto_create_topic(topic_name).await {
                    Ok(_metadata) => {
                        tracing::info!("Successfully auto-created topic '{}' with Raft integration", topic_name);
                    }
                    Err(e) => {
                        tracing::error!("Failed to auto-create topic '{}': {:?}", topic_name, e);
                        // Continue trying to create other topics
                    }
                }
            }
        }

        Ok(())
    }

    /// Flush all partition buffers to storage
    pub async fn flush_all_partitions(&self) -> Result<()> {
        self.produce_handler.flush_all_partitions().await
    }
}

